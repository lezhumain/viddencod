#include "qaudiodecoder.hpp"
#include <QMessageBox>
#include <QDebug>


QAudioDecoder::QAudioDecoder()
{
    InitVars();
    initCodec();
}

void QAudioDecoder::InitVars()
{
   ok=false;
   pFormatCtx=0;
   pCodecCtx=0;
   pCodec=0;
   pFrame=0;
   pAudioFrame=0;
   pFrameRGB=0;
   buffer=0;
   img_convert_ctx=0;
}

bool QAudioDecoder::initCodec()
{
   ffmpeg::avcodec_init();
   ffmpeg::avcodec_register_all();
   ffmpeg::av_register_all();

   printf("License: %s\n",ffmpeg::avformat_license());
   printf("AVCodec version %d\n",ffmpeg::avformat_version());
   printf("AVFormat configuration: %s\n",ffmpeg::avformat_configuration());

   return true;
}

void QAudioDecoder::close()
{
   if(!ok)
      return;

   // Free the RGB image
   if(buffer)
      delete [] buffer;

   // Free the YUV frame
//   if(pFrame)
//      av_free(pFrame);

   // Free the RGB frame
//   if(pFrameRGB)
//      av_free(pFrameRGB);

   // Close the codec
   if(pCodecCtx)
      avcodec_close(pCodecCtx);

   // Close the video file
   if(pFormatCtx)
      av_close_input_file(pFormatCtx);

   InitVars();
}

bool QAudioDecoder::openFile(QString filename)
{
   // Close last video..
   close();

   LastLastFrameTime=INT_MIN;       // Last last must be small to handle the seek well
   LastFrameTime=0;
   LastLastFrameNumber=INT_MIN;
   LastFrameNumber=0;
   DesiredFrameTime=DesiredFrameNumber=0;
   LastFrameOk=false;


   // Open video file
   if(av_open_input_file(&pFormatCtx, filename.toStdString().c_str(), NULL, 0, NULL)!=0)
       return false; // Couldn't open file

   // Retrieve stream information
   if(av_find_stream_info(pFormatCtx)<0)
       return false; // Couldn't find stream information

   // Dump information about file onto standard error
   dump_format(pFormatCtx, 0, filename.toStdString().c_str(), false);

   // Find the first video stream
        //   videoStream=-1;
        //   for(unsigned i=0; i<pFormatCtx->nb_streams; i++)
        //       if(pFormatCtx->streams[i]->codec->codec_type==ffmpeg::AVMEDIA_TYPE_VIDEO)
        //       {
        //           videoStream=i;
        //           break;
        //       }
        //   if(videoStream==-1)
        //       return false; // Didn't find a video stream
   // Find the first audio stream
   audioStream=-1;
   for(unsigned i=0; i<pFormatCtx->nb_streams; i++)
       if(pFormatCtx->streams[i]->codec->codec_type==ffmpeg::AVMEDIA_TYPE_AUDIO)
       {
           audioStream=i;
           break;
       }
   if(audioStream==-1)
       return false; // Didn't find an audio stream

   // Get a pointer to the codec context for the audio stream
   pCodecCtx=pFormatCtx->streams[audioStream]->codec;

   // Find the decoder for the video stream
        //   pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
        //   if(pCodec==NULL)
        //       return false; // Codec not found
   // Find the decoder for the audio stream
   pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
   if(pCodec==NULL)
       return false; // Codec not found

   // Open codec
   if(avcodec_open(pCodecCtx, pCodec)<0)
       return false; // Could not open codec

   // Hack to correct wrong frame rates that seem to be generated by some
   // codecs
  if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
     pCodecCtx->time_base.den=1000;

   // Allocate audio frame
   pFrame=ffmpeg::avcodec_alloc_frame();

   // Allocate an AVFrame structure
   pFrameRGB=ffmpeg::avcodec_alloc_frame();
   if(pFrameRGB==NULL)
       return false;

   // Determine required buffer size and allocate buffer
   numBytes=ffmpeg::avpicture_get_size(ffmpeg::PIX_FMT_RGB24, pCodecCtx->width,pCodecCtx->height);
   buffer=new uint8_t[numBytes];

   // Assign appropriate parts of buffer to image planes in pFrameRGB
   avpicture_fill((ffmpeg::AVPicture *)pFrameRGB, buffer, ffmpeg::PIX_FMT_RGB24,
       pCodecCtx->width, pCodecCtx->height);

   ok=true;
   return true;
}

bool QAudioDecoder::isOk()
{
   return ok;
}

void QAudioDecoder::dumpFormat(ffmpeg::AVFormatContext *ic,
                 int index,
                 const char *url,
                 int is_output)
{
    //int i;
    uint8_t *printed = (uint8_t*)ffmpeg::av_mallocz(ic->nb_streams);
    if (ic->nb_streams && !printed)
        return;

    printf("AV_TIME_BASE: %d\n",AV_TIME_BASE);

    printf("%s #%d, %s,\n %s '%s':\n",
            is_output ? "Output" : "Input",
            index,
            is_output ? ic->oformat->name : ic->iformat->name,
            is_output ? "to" : "from", url);
    if (!is_output) {
        printf("  Duration: ");
        //if (ic->duration != AV_NOPTS_VALUE)
        {
            int hours, mins, secs, us;
            secs = ic->duration / AV_TIME_BASE;
            us = ic->duration % AV_TIME_BASE;
            mins = secs / 60;
            secs %= 60;
            hours = mins / 60;
            mins %= 60;
            printf("%02d:%02d:%02d.%02d\n", hours, mins, secs,
                   (100 * us) / AV_TIME_BASE);
        } //else {
            //printf("N/A");
        //}
        //if (ic->start_time != AV_NOPTS_VALUE)
        {
            int secs, us;
            printf(", start: ");
            secs = ic->start_time / AV_TIME_BASE;
            us = ic->start_time % AV_TIME_BASE;
            printf("%d.%06d\n",
                   secs, (int)ffmpeg::av_rescale(us, 1000000, AV_TIME_BASE));
        }
        printf(", bitrate: ");
        if (ic->bit_rate) {
            printf("%d kb/s\n", ic->bit_rate / 1000);
        } else {
            printf("N/A\n");
        }
        printf("\n");
    }
    if(ic->nb_programs) {
        unsigned int j, total=0;
        for(j=0; j<ic->nb_programs; j++) {
            ffmpeg::AVMetadataTag *name = av_metadata_get(ic->programs[j]->metadata,
                                                  "name", NULL, 0);
            printf("  Program %d %s\n", ic->programs[j]->id,
                   name ? name->value : "");
            /*for(k=0; k<ic->programs[j]->nb_stream_indexes; k++) {
                dump_stream_format(ic, ic->programs[j]->stream_index[k], index, is_output);
                printed[ic->programs[j]->stream_index[k]] = 1;
            }*/
            total += ic->programs[j]->nb_stream_indexes;
        }
        if (total < ic->nb_streams)
            printf( "  No Program\n");
    }
    /*for(i=0;i<ic->nb_streams;i++)
        if (!printed[i])
            ffmpeg::dump_stream_format(ic, i, index, is_output);*/

    if (ic->metadata) {
        ffmpeg::AVMetadataTag *tag=NULL;
        printf("  Metadata\n");
        while((tag=av_metadata_get(ic->metadata, "", tag, AV_METADATA_IGNORE_SUFFIX))) {
            printf("    %-16s: %s\n", tag->key, tag->value);
        }
    }
    ffmpeg::av_free(printed);
}

int QAudioDecoder::getVideoLengthMs()
{
   if(!isOk())
      return -1;


   int secs = pFormatCtx->duration / AV_TIME_BASE;
   int us = pFormatCtx->duration % AV_TIME_BASE;
   int l = secs*1000 + us/1000;


   dumpFormat(pFormatCtx,audioStream,"test video",0);

   return l;
}

bool QAudioDecoder::getAudioFrame(int16_t& audioSample, int *effectiveframenumber, int *effectiveframetime, int *desiredframenumber, int *desiredframetime)
{
   audioSample = LastAudioFrame;

   if(effectiveframenumber)
      *effectiveframenumber = LastFrameNumber;
   if(effectiveframetime)
      *effectiveframetime = LastFrameTime;
   if(desiredframenumber)
      *desiredframenumber = DesiredFrameNumber;
   if(desiredframetime)
      *desiredframetime = DesiredFrameTime;

   //printf("getFrame. Returning valid? %s. Desired %d @ %d. Effective %d @ %d\n",LastFrameOk?"yes":"no",DesiredFrameNumber,DesiredFrameTime,LastFrameNumber,LastFrameTime);

   return LastFrameOk;
}

/**
   Decodes the audio stream until the first frame with number larger or equal than 'after' is found.

   Returns:
   - true if a frame is found, false otherwise.
   - the image as a QImage if img is non-null
   - time frame time, if frametime is non-null
   - the frame number, if framenumber is non-null

   All times are in milliseconds.
**/
bool QAudioDecoder::decodeSeekFrame(int after)
{
   if(!ok)
      return false;

   //printf("decodeSeekFrame. after: %d. LLT: %d. LT: %d. LLF: %d. LF: %d. LastFrameOk: %d.\n",after,LastLastFrameTime,LastFrameTime,LastLastFrameNumber,LastFrameNumber,(int)LastFrameOk);



   // If the last decoded frame satisfies the time condition we return it
   //if( after!=-1 && ( LastDataInvalid==false && after>=LastLastFrameTime && after <= LastFrameTime))
   if( after!=-1 && ( LastFrameOk==true && after>=LastLastFrameNumber && after <= LastFrameNumber))
   {
      // This is the frame we want to return

      // Compute desired frame time
      ffmpeg::AVRational millisecondbase = {1, 1000};
      DesiredFrameTime = ffmpeg::av_rescale_q(after,pFormatCtx->streams[audioStream]->time_base,millisecondbase);

      //printf("Returning already available frame %d @ %d. DesiredFrameTime: %d\n",LastFrameNumber,LastFrameTime,DesiredFrameTime);

      return true;
   }

   // The last decoded frame wasn't ok; either we need any new frame (after=-1), or a specific new frame with time>after

   bool done=false;
   while(!done)
   {
      // Read a frame
      if(av_read_frame(pFormatCtx, &packet)<0)
         return false;                             // Frame read failed (e.g. end of stream)

      //printf("Packet of stream %d, size %d\n",packet.stream_index,packet.size);

      if(packet.stream_index==audioStream)
      {
         // Is this a packet from the audio stream -> decode audio frame

         int frameSize;
         avcodec_decode_audio3(pCodecCtx,pAudioFrame,&frameSize,&packet);

         //printf("used %d out of %d bytes\n",len,packet.size);

         //printf("Frame type: ");
         //if(pFrame->pict_type == FF_B_TYPE)
         //   printf("B\n");
         //else if (pFrame->pict_type == FF_I_TYPE)
         //   printf("I\n");
         //else
         //   printf("P\n");


         /*printf("codecctx time base: num: %d den: %d\n",pCodecCtx->time_base.num,pCodecCtx->time_base.den);
         printf("formatctx time base: num: %d den: %d\n",pFormatCtx->streams[audioStream]->time_base.num,pFormatCtx->streams[audioStream]->time_base.den);
         printf("pts: %ld\n",pts);
         printf("dts: %ld\n",dts);*/




         // Did we get a audio frame?
         if(frameSize > 0)
         {
            ffmpeg::AVRational millisecondbase = {1, 1000};
            int f = packet.dts;
            int t = ffmpeg::av_rescale_q(packet.dts,pFormatCtx->streams[audioStream]->time_base,millisecondbase);
            if(LastFrameOk==false)
            {
               LastFrameOk=true;
               LastLastFrameTime=LastFrameTime=t;
               LastLastFrameNumber=LastFrameNumber=f;
            }
            else
            {
               // If we decoded 2 frames in a row, the last times are okay
               LastLastFrameTime = LastFrameTime;
               LastLastFrameNumber = LastFrameNumber;
               LastFrameTime=t;
               LastFrameNumber=f;
            }
            //printf("Frame %d @ %d. LastLastT: %d. LastLastF: %d. LastFrameOk: %d\n",LastFrameNumber,LastFrameTime,LastLastFrameTime,LastLastFrameNumber,(int)LastFrameOk);

            // Is this frame the desired frame?
            if(after==-1 || LastFrameNumber>=after)
            {
               // It's the desired frame

               // Convert the image format (init the context the first time)
               int w = pCodecCtx->width;
               int h = pCodecCtx->height;
               img_convert_ctx = ffmpeg::sws_getCachedContext(img_convert_ctx,w, h, pCodecCtx->pix_fmt, w, h, ffmpeg::PIX_FMT_RGB24, SWS_BICUBIC, NULL, NULL, NULL);

               if(img_convert_ctx == NULL)
               {
                  printf("Cannot initialize the conversion context!\n");
                  return false;
               }
               ffmpeg::sws_scale(img_convert_ctx, pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);

               // Convert the frame to QImage
               LastFrame=QImage(w,h,QImage::Format_RGB888);

               for(int y=0;y<h;y++)
                  memcpy(LastFrame.scanLine(y),pFrameRGB->data[0]+y*pFrameRGB->linesize[0],w*3);

               // Set the time
               DesiredFrameTime = ffmpeg::av_rescale_q(after,pFormatCtx->streams[audioStream]->time_base,millisecondbase);
               LastFrameOk=true;


               done = true;

            } // frame of interest
         }  // frameFinished
      }  // stream_index==audioStream
      av_free_packet(&packet);      // Free the packet that was allocated by av_read_frame
   }
   //printf("Returning new frame %d @ %d. LastLastT: %d. LastLastF: %d. LastFrameOk: %d\n",LastFrameNumber,LastFrameTime,LastLastFrameTime,LastLastFrameNumber,(int)LastFrameOk);
   //printf("\n");
   return done;   // done indicates whether or not we found a frame
}

/**
   \brief Decodes the next frame in the audio stream
**/
bool QAudioDecoder::seekNextAudioFrame()
{
   bool ret = decodeSeekFrame(DesiredFrameNumber+1);

   if(ret)
      DesiredFrameNumber++;   // Only updates the DesiredFrameNumber if we were successful in getting that frame
   else
      LastFrameOk=false;      // We didn't find the next frame (e.g. seek out of range) - mark we don't know where we are.
   return ret;
}

QList<int16_t> QAudioDecoder::getAllAudioFrames()
{
    short frameRate = 25;
    int lengthMs = getVideoLengthMs();
    qWarning() << "length" << lengthMs ;

    int maxFrames = lengthMs * frameRate / 1000;
    maxFrames = maxFrames < 0 ? 50000 : maxFrames;
    qWarning() << "maxframes" << maxFrames ;

    QList<int16_t> listIm;

    for(int i = 0; i < maxFrames; ++i)
    {
        int16_t img;
        int eframeNumbern, frameTime;
        if(!getAudioFrame(img,&eframeNumbern,&frameTime))
        {
//           QMessageBox::critical(this,"Error","Error decoding the frame");
            qWarning() << "Error decoding the frame";
            listIm.clear();
            break;
        }
        listIm.append(img);

        if(!seekNextAudioFrame() || i == 1000000)
        {
            qWarning() << "Current frame:" << eframeNumbern << "[i =" << i << "]";
            break;
        }
    }

    return listIm;
}
